
## 1) 仓库改动清单（按目录/模块拆分）

### A. 构建与依赖（让工程“能编出 CUDA 版”）

1. **SUNDIALS 安装脚本升级为“带 GPU 特性”的构建**
    
    - 修改 `configure`（或新增 `configure_cuda`）：
        
        - CMake 配置加入 `-D ENABLE_CUDA=ON`（以及你需要的包：CVODE 必须，若未来上 ARKODE/IMEX 也可一起开）。SUNDIALS 官方说明 GPU 特性需显式开启，并强调 host/device coherency 由用户负责。([SUNDIALS](https://sundials.readthedocs.io/en/latest/sundials/GPU_link.html "1.9. Features for GPU Accelerated Computing — User Documentation for SUNDIALS  documentation"))
            
        - 显式设置 `-D CMAKE_CUDA_ARCHITECTURES=<xx>`（别用过时的 `CUDA_ARCH=sm_70` 这种写法，社区里提到要用 `CMAKE_CUDA_ARCHITECTURES`）。([Google Groups](https://groups.google.com/g/sundials-users/c/76pr2F9evRM?utm_source=chatgpt.com "[sundials-users] Build failing with \"Unknown CMake command print_warning\""))
            
    - 修改 `Script/installSundials.sh`（若存在并在用）：同上，确保装出来的库里包含 `libsundials_nveccuda`（NVECTOR_CUDA）。NVECTOR_CUDA 文档明确需要链接该库。([SUNDIALS](https://sundials.readthedocs.io/en/latest/nvectors/NVector_links.html "8.9. The NVECTOR_SERIAL Module — User Documentation for SUNDIALS  documentation"))
        
2. **Makefile 增加 CUDA 构建目标**
    
    - 新增 target：`shud_cuda`（或 `shud_gpu`）
        
    - 编译器：`nvcc`（或 `nvc++`/`clang++ --cuda`，但第一版用 nvcc 最稳）
        
    - 链接库至少包含：
        
        - `-lsundials_cvode`
            
        - `-lsundials_nveccuda`（关键）
            
        - `-lcudart`（以及你用到的 cuBLAS/cuSPARSE/cuSOLVER 时再加）
            
    - 增加宏：`-D_CUDA_ON`（与你们已有 `_OPENMP_ON` 类似）
        
3. **README/文档补充：如何安装 GPU 版 SUNDIALS、如何编译与运行 shud_cuda**
    
    - 说明“运行时选择 CPU/OMP/CUDA backend”的参数（见后面 CLI）。
        

---

### B. 运行时 Backend 选择（CPU / OMP / CUDA 三态）

4. **CLI 增加参数**（建议在 `src/CommandIn.*` 里）
    
    - `--backend cpu|omp|cuda`
        
    - 或 `--cuda 1`（更快但不如三态清晰）
        
    - 将选择写入全局配置（你们已有 `global_implicit_mode/global_verbose_mode` 等全局变量风格），例如 `global_backend = BACKEND_CUDA`
        

---

### C. N_Vector 与数据驻留（端到端 GPU 的核心）

5. **`src/Model/shud.cpp`：为 CUDA backend 创建 NVECTOR_CUDA**
    
    - 当前逻辑是 `N_VNew_Serial` / `N_VNew_OpenMP`：
        
        - CUDA backend 改为 `udata = N_VNew_Cuda(NY, sunctx)` 或 `N_VNewManaged_Cuda(...)`（第一版更建议先用 **unmanaged**，减少 UVM 不确定性；需要频繁读 host 时再评估 managed）。NVECTOR_CUDA 提供这些构造器。([SUNDIALS](https://sundials.readthedocs.io/en/latest/nvectors/NVector_links.html "8.9. The NVECTOR_SERIAL Module — User Documentation for SUNDIALS  documentation"))
            
    - 注意：NVECTOR_CUDA __不提供 NV_DATA__ 宏_*，要用 `N_VGetDeviceArrayPointer_Cuda / N_VGetHostArrayPointer_Cuda` 这类 accessor。([SUNDIALS](https://sundials.readthedocs.io/en/latest/nvectors/NVector_links.html "8.9. The NVECTOR_SERIAL Module — User Documentation for SUNDIALS  documentation"))
        
6. **输出/诊断前的 Host 同步（避免“读到旧数据”）**
    
    - 你们很多输出函数（`MD->summary`, `PrintInit`, flood warning 等）会读取 `udata`：
        
        - CUDA backend：在读取 host 数据前调用 `N_VCopyFromDevice_Cuda(udata)`，然后用 `N_VGetHostArrayPointer_Cuda(udata)` 取 host 指针。NVECTOR_CUDA 明确提供 CopyFromDevice/CopyToDevice。([SUNDIALS](https://sundials.readthedocs.io/en/latest/nvectors/NVector_links.html "8.9. The NVECTOR_SERIAL Module — User Documentation for SUNDIALS  documentation"))
            
    - 相反，如果你们在 CPU 上改了 `udata`（例如手动设 IC），要 `N_VCopyToDevice_Cuda` 保持一致。([SUNDIALS](https://sundials.readthedocs.io/en/latest/nvectors/NVector_links.html "8.9. The NVECTOR_SERIAL Module — User Documentation for SUNDIALS  documentation"))
        

---

### D. RHS（f）重构：从“CPU 循环”变成“GPU kernel + 最薄的 host wrapper”

7. **新增 CUDA RHS wrapper：`f_cuda`**
    
    - 新文件建议：
        
        - `src/GPU/f_cuda.cpp`（host 侧，签名仍是 `int f(realtype t, N_Vector y, N_Vector ydot, void* user)`）
            
        - `src/GPU/rhs_kernels.cu`（真正的 kernel）
            
    - `f_cuda` 做的事尽量少：
        
        1. `auto* dY = N_VGetDeviceArrayPointer_Cuda(CV_Y);`
            
        2. `auto* dDY = N_VGetDeviceArrayPointer_Cuda(CV_Ydot);` ([SUNDIALS](https://sundials.readthedocs.io/en/latest/nvectors/NVector_links.html "8.9. The NVECTOR_SERIAL Module — User Documentation for SUNDIALS  documentation"))
            
        3. 调用 kernels 完成你们现在 `MD->f_update / f_loop / f_applyDY` 的工作（但在设备端）
            
8. **修改 `src/Model/f.cpp`：按 backend 分发**
    
    - 现有 `f()` 里用 `NV_DATA_S` / `NV_DATA_OMP`：
        
        - 增加 `#ifdef _CUDA_ON` 分支：直接调用 `f_cuda(t, CV_Y, CV_Ydot, DS)`（或把现有 `f` 改成分发器）
            
    - 同理：`f_surf / f_unsat / f_gw / f_river / f_lake` 若也要 GPU（第二阶段再做也行）
        

---

### E. 设备侧 Model 数据（静态参数 + forcing + 拓扑索引）

9. **新增“GPU 常驻数据结构”（建议集中在 `src/GPU/DeviceContext.*`）**
    
    - 目标：让 kernel 不要访问 `Model_Data` 的复杂 C++ 对象图，而是访问扁平数组。
        
    - 典型内容（按你们水文网格/河网常见模式）：
        
        - 静态：`area`, `z`, `soil`, `Ks`, `porosity`, `slope`, `aspect`, …（按你们已有数组）
            
        - 拓扑：element 邻接（edge 列表 + 两端 cell id）、河段-单元映射、lake 连接等
            
        - forcing：降雨、温度、辐射、风、湿度等（你们 `TimeSeriesData` 的结果）
            
    - 组织方式：
        
        - **SoA（Structure of Arrays）**：每个字段一根数组，避免 AoS
            
10. **`Model_Data` 增加 GPU 生命周期接口**
    

- 在 `Model_Data` 里加：
    
    - `void gpuInit(SUNContext, /*可选 stream */);`
        
    - `void gpuFree();`
        
    - `void gpuUpdateForcing(double t);`（把当前步 forcing 推到 device，或做 device 侧插值）
        
- 在 `SHUD()` 初始化阶段（`loadinput/initialize` 后）调用 `MD->gpuInit()`；结束前 `gpuFree()`
    

---

### F. kernel 组织（吞吐与可维护性的折中）

11. **拆分 RHS 为 2~3 个大 kernel（而不是很多小 kernel）**
    

- 你们现有 CPU 流程：`f_update -> f_loop -> f_applyDY`
    
- GPU 版建议：
    
    - Kernel1：计算所有“局部源项”（每 cell 独立）
        
    - Kernel2：计算所有“边通量/邻接交换”（edge 并行）
        
    - Kernel3：把 edge_flux 归并到 cell 的 dY（或与 Kernel2 融合，取决于原子开销）
        
- SUNDIALS 也强调：RHS 应尽量只在 device 上操作数据，否则数据搬运会毁掉性能。([SUNDIALS](https://sundials.readthedocs.io/en/latest/sundials/GPU_link.html "1.9. Features for GPU Accelerated Computing — User Documentation for SUNDIALS  documentation"))
    

12. **边通量累加策略（性能关键点之一）**
    

- 两种实现路径（第一版建议先做“正确+可跑”，再压榨性能）：
    
    - **两段式**：edge 计算写 `edge_flux[e]`（无冲突）→ 再按 cell gather/reduce（可控）
        
    - **原子 scatter**：edge 直接对两端 cell `atomicAdd`（实现快，但可能在高度数网格上被原子瓶颈卡住）
        

---

### G. 线性求解/预条件（方案 A 后半程的“上限”）

13. **第一版先跑通：继续用 `SUNLinSol_SPGMR`（Krylov）**
    

- GPU doc 里列出 SPGMR 等 Krylov 求解器在 GPU 场景可继承 NVECTOR 支持。([SUNDIALS](https://sundials.readthedocs.io/en/latest/sundials/GPU_link.html "1.9. Features for GPU Accelerated Computing — User Documentation for SUNDIALS  documentation"))
    

14. **第二版开始做 GPU 预条件器（决定隐式模式能快多少）**
    

- CVODE 明确支持 `CVodeSetPreconditioner(psetup, psolve)`。([SUNDIALS](https://sundials.readthedocs.io/en/v6.1.0/cvode/Usage/index.html?utm_source=chatgpt.com "4.4. Using CVODE for IVP Solution — User Documentation for SUNDIALS ..."))
    
- 现实可落地的 GPU 预条件器路线：
    
    - Block-Jacobi（每 cell/小块一个小系统）+ batched solve
        
    - 或引入 SUNDIALS 的 GPU 线性代数模块（如 `SUNLINSOL_CUSOLVERSP`/`SUNMATRIX_CUSPARSE` 等在 GPU 模块列表中）。([SUNDIALS](https://sundials.readthedocs.io/en/latest/sundials/GPU_link.html "1.9. Features for GPU Accelerated Computing — User Documentation for SUNDIALS  documentation"))
        

---

### H. 基准、回归与 Profiling（没有这块很难“真的提速”）

15. **新增 benchmark 脚本与性能计数**
    

- `scripts/validate_cpu_omp_cuda.sh`
    
- 输出：wall time、`MD->nFCall`、CVODE step/liniter 统计（你们已有 `PrintFinalStats`）
    

16. **加入 NVTX 标记 + Nsight**
    

- 在 RHS wrapper 周围加 NVTX range（方便 Nsight Systems 看时间线）
    

---
